{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This file is for analysis wavelengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from time import time\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "#from sklearn.datasets import make_moons, make_circles, make_classification\n",
    "#from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try to find best bands for classify Healthy and disease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_to_name = {0:'Healthy', 1: 'Disease'}\n",
    "name_to_label = {'Healthy':0, 'Disease':1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>394.6</th>\n",
       "      <th>396.7</th>\n",
       "      <th>398.7</th>\n",
       "      <th>400.8</th>\n",
       "      <th>402.8</th>\n",
       "      <th>404.9</th>\n",
       "      <th>406.9</th>\n",
       "      <th>409</th>\n",
       "      <th>411</th>\n",
       "      <th>...</th>\n",
       "      <th>866.7</th>\n",
       "      <th>868.8</th>\n",
       "      <th>870.9</th>\n",
       "      <th>872.9</th>\n",
       "      <th>875</th>\n",
       "      <th>877</th>\n",
       "      <th>879.1</th>\n",
       "      <th>881.1</th>\n",
       "      <th>883.2</th>\n",
       "      <th>885.2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.04827</td>\n",
       "      <td>0.04468</td>\n",
       "      <td>0.04008</td>\n",
       "      <td>0.03521</td>\n",
       "      <td>0.03030</td>\n",
       "      <td>0.02578</td>\n",
       "      <td>0.02212</td>\n",
       "      <td>0.01985</td>\n",
       "      <td>0.01826</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3162</td>\n",
       "      <td>0.3168</td>\n",
       "      <td>0.3175</td>\n",
       "      <td>0.3180</td>\n",
       "      <td>0.3184</td>\n",
       "      <td>0.3187</td>\n",
       "      <td>0.3190</td>\n",
       "      <td>0.3194</td>\n",
       "      <td>0.3195</td>\n",
       "      <td>0.3194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.05322</td>\n",
       "      <td>0.04898</td>\n",
       "      <td>0.04387</td>\n",
       "      <td>0.03805</td>\n",
       "      <td>0.03224</td>\n",
       "      <td>0.02683</td>\n",
       "      <td>0.02242</td>\n",
       "      <td>0.01950</td>\n",
       "      <td>0.01754</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3379</td>\n",
       "      <td>0.3388</td>\n",
       "      <td>0.3393</td>\n",
       "      <td>0.3402</td>\n",
       "      <td>0.3408</td>\n",
       "      <td>0.3412</td>\n",
       "      <td>0.3415</td>\n",
       "      <td>0.3417</td>\n",
       "      <td>0.3419</td>\n",
       "      <td>0.3416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.04710</td>\n",
       "      <td>0.04375</td>\n",
       "      <td>0.03963</td>\n",
       "      <td>0.03504</td>\n",
       "      <td>0.03022</td>\n",
       "      <td>0.02590</td>\n",
       "      <td>0.02229</td>\n",
       "      <td>0.01998</td>\n",
       "      <td>0.01833</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3627</td>\n",
       "      <td>0.3634</td>\n",
       "      <td>0.3638</td>\n",
       "      <td>0.3643</td>\n",
       "      <td>0.3648</td>\n",
       "      <td>0.3651</td>\n",
       "      <td>0.3651</td>\n",
       "      <td>0.3649</td>\n",
       "      <td>0.3651</td>\n",
       "      <td>0.3648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.04965</td>\n",
       "      <td>0.04648</td>\n",
       "      <td>0.04230</td>\n",
       "      <td>0.03775</td>\n",
       "      <td>0.03321</td>\n",
       "      <td>0.02890</td>\n",
       "      <td>0.02520</td>\n",
       "      <td>0.02265</td>\n",
       "      <td>0.02040</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3373</td>\n",
       "      <td>0.3383</td>\n",
       "      <td>0.3390</td>\n",
       "      <td>0.3399</td>\n",
       "      <td>0.3406</td>\n",
       "      <td>0.3412</td>\n",
       "      <td>0.3419</td>\n",
       "      <td>0.3423</td>\n",
       "      <td>0.3429</td>\n",
       "      <td>0.3432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.04562</td>\n",
       "      <td>0.04221</td>\n",
       "      <td>0.03784</td>\n",
       "      <td>0.03332</td>\n",
       "      <td>0.02895</td>\n",
       "      <td>0.02493</td>\n",
       "      <td>0.02176</td>\n",
       "      <td>0.02012</td>\n",
       "      <td>0.01829</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2413</td>\n",
       "      <td>0.2420</td>\n",
       "      <td>0.2431</td>\n",
       "      <td>0.2438</td>\n",
       "      <td>0.2444</td>\n",
       "      <td>0.2452</td>\n",
       "      <td>0.2458</td>\n",
       "      <td>0.2463</td>\n",
       "      <td>0.2465</td>\n",
       "      <td>0.2471</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 241 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label    394.6    396.7    398.7    400.8    402.8    404.9    406.9  \\\n",
       "0      0  0.04827  0.04468  0.04008  0.03521  0.03030  0.02578  0.02212   \n",
       "1      0  0.05322  0.04898  0.04387  0.03805  0.03224  0.02683  0.02242   \n",
       "2      0  0.04710  0.04375  0.03963  0.03504  0.03022  0.02590  0.02229   \n",
       "3      0  0.04965  0.04648  0.04230  0.03775  0.03321  0.02890  0.02520   \n",
       "4      0  0.04562  0.04221  0.03784  0.03332  0.02895  0.02493  0.02176   \n",
       "\n",
       "       409      411   ...     866.7   868.8   870.9   872.9     875     877  \\\n",
       "0  0.01985  0.01826   ...    0.3162  0.3168  0.3175  0.3180  0.3184  0.3187   \n",
       "1  0.01950  0.01754   ...    0.3379  0.3388  0.3393  0.3402  0.3408  0.3412   \n",
       "2  0.01998  0.01833   ...    0.3627  0.3634  0.3638  0.3643  0.3648  0.3651   \n",
       "3  0.02265  0.02040   ...    0.3373  0.3383  0.3390  0.3399  0.3406  0.3412   \n",
       "4  0.02012  0.01829   ...    0.2413  0.2420  0.2431  0.2438  0.2444  0.2452   \n",
       "\n",
       "    879.1   881.1   883.2   885.2  \n",
       "0  0.3190  0.3194  0.3195  0.3194  \n",
       "1  0.3415  0.3417  0.3419  0.3416  \n",
       "2  0.3651  0.3649  0.3651  0.3648  \n",
       "3  0.3419  0.3423  0.3429  0.3432  \n",
       "4  0.2458  0.2463  0.2465  0.2471  \n",
       "\n",
       "[5 rows x 241 columns]"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_data = pd.read_excel(\"full_data.xlsx\")\n",
    "full_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create X and label for training, test\n",
    "\n",
    "Xarray-like of shape (n_samples, n_features)\n",
    "Training vector, where n_samples is the number of samples and n_features is the number of features.\n",
    "\n",
    "yarray-like of shape (n_samples, n_output) or (n_samples,), default=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label = full_data['label'].tolist()\n",
    "label = np.asarray(label).reshape(-1,)\n",
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = full_data.columns.tolist()\n",
    "cols = cols[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.01768],\n",
       "       [0.0179 ],\n",
       "       [0.01819],\n",
       "       ...,\n",
       "       [0.02279],\n",
       "       [0.02006],\n",
       "       [0.02306]])"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = full_data[cols[10]].tolist()\n",
    "x = np.asarray(x).reshape(-1,1)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, label, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2992,)"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting the classifier to the training set\n",
      "Set Grid parameters\n",
      "Start to fit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Anaconda3\\envs\\py2\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 331.124s\n",
      "Best estimator found by grid search:\n",
      "SVC(C=500.0, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma=0.05, kernel='rbf',\n",
      "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n"
     ]
    }
   ],
   "source": [
    "# #############################################################################\n",
    "# Train a SVM classification model\n",
    "\n",
    "print(\"Fitting the classifier to the training set\")\n",
    "t0 = time()\n",
    "param_grid = {'kernel':['rbf','sigmod','linear'],'C': [1e2,5e2,1e3, 5e3, 1e4],\n",
    "              'gamma': [0.001, 0.005, 0.01,0.05,0.1,0.2]}\n",
    "print(\"Set Grid parameters\")\n",
    "clf = GridSearchCV(\n",
    "    SVC(class_weight='balanced',probability=True), param_grid, cv=10)\n",
    "print(\"Start to fit\")\n",
    "clf = clf.fit(x_train, y_train)\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "print(\"Best estimator found by grid search:\")\n",
    "print(clf.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7287607170693686"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1283, 2)"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = clf.predict_proba(x_test)\n",
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.75      , 0.25      ],\n",
       "       [0.90728477, 0.09271523],\n",
       "       [0.83333333, 0.16666667],\n",
       "       ...,\n",
       "       [0.83870968, 0.16129032],\n",
       "       [0.90728477, 0.09271523],\n",
       "       [1.        , 0.        ]])"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.75      , 0.25      ],\n",
       "        [0.90728477, 0.09271523],\n",
       "        [0.83333333, 0.16666667],\n",
       "        [1.        , 0.        ],\n",
       "        [0.78947368, 0.21052632],\n",
       "        [1.        , 0.        ],\n",
       "        [0.82954545, 0.17045455],\n",
       "        [1.        , 0.        ],\n",
       "        [0.78070175, 0.21929825],\n",
       "        [0.78070175, 0.21929825]]), array([[1.        , 0.        ],\n",
       "        [0.90728477, 0.09271523],\n",
       "        [1.        , 0.        ],\n",
       "        [0.        , 1.        ],\n",
       "        [1.        , 0.        ],\n",
       "        [1.        , 0.        ],\n",
       "        [1.        , 0.        ],\n",
       "        [0.83870968, 0.16129032],\n",
       "        [0.90728477, 0.09271523]]))"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[:10,:], y_pred[-10:-1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7730597800293019, 0.22694021997069808)"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test,y_pred[:,1]), roc_auc_score(y_test,y_pred[:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = full_data['label'].tolist()\n",
    "label = np.asarray(label).reshape(-1,1)\n",
    "cols = full_data.columns.tolist()\n",
    "cols = cols[1:]\n",
    "x = full_data[cols[10]].tolist()\n",
    "x = np.asarray(x).reshape(-1,1)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, label, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting the classifier to the training set\n",
      "Set Grid parameters\n",
      "Start to fit\n",
      "done in 1.387s\n",
      "Best estimator found by grid search:\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=19,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best')\n"
     ]
    }
   ],
   "source": [
    "print(\"Fitting the classifier to the training set\")\n",
    "t0 = time()\n",
    "param_grid = {'max_depth': range(1,20), 'criterion':['gini','entropy']}\n",
    "print(\"Set Grid parameters\")\n",
    "clf = GridSearchCV(\n",
    "    DecisionTreeClassifier(), param_grid, cv=10)\n",
    "print(\"Start to fit\")\n",
    "clf = clf.fit(x_train, y_train)\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "print(\"Best estimator found by grid search:\")\n",
    "print(clf.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8620420888542478"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = clf.score(x_test, y_test)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict_proba(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.75      , 0.25      ],\n",
       "        [0.90728477, 0.09271523],\n",
       "        [0.83333333, 0.16666667],\n",
       "        [1.        , 0.        ],\n",
       "        [0.78947368, 0.21052632],\n",
       "        [1.        , 0.        ],\n",
       "        [0.82954545, 0.17045455],\n",
       "        [1.        , 0.        ],\n",
       "        [0.78070175, 0.21929825],\n",
       "        [0.78070175, 0.21929825]]), array([[1.        , 0.        ],\n",
       "        [0.90728477, 0.09271523],\n",
       "        [1.        , 0.        ],\n",
       "        [0.        , 1.        ],\n",
       "        [1.        , 0.        ],\n",
       "        [1.        , 0.        ],\n",
       "        [1.        , 0.        ],\n",
       "        [0.83870968, 0.16129032],\n",
       "        [0.90728477, 0.09271523]]))"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[:10,:], y_pred[-10:-1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "234"
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[(y_pred[:,1] == 1)].size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "294"
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7730597800293019, 0.22694021997069808)"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test,y_pred[:,1]), roc_auc_score(y_test,y_pred[:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = full_data['label'].tolist()\n",
    "label = np.asarray(label).reshape(-1,)\n",
    "cols = full_data.columns.tolist()\n",
    "cols = cols[1:]\n",
    "x = full_data[cols[10]].tolist()\n",
    "x = np.asarray(x).reshape(-1,1)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, label, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier()\n",
    "clf.fit(x_train, y_train)\n",
    "clf.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To train each wavelength and get scores\n",
    "result_scores = []\n",
    "for col in cols:\n",
    "    # Xarray-like of shape (n_samples, n_features) Training vector, \n",
    "    # where n_samples is the number of samples and n_features is the number of features.\n",
    "    x = full_data[col].tolist()\n",
    "    x = np.asarray(x).reshape(-1,1)\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, label, test_size=0.2, random_state=42)\n",
    "\n",
    "    clf = RandomForestClassifier(n_estimators=100, max_depth=19)\n",
    "    clf.fit(x_train, y_train)\n",
    "    score = clf.score(x_test, y_test)\n",
    "\n",
    "    result_score = dict()\n",
    "    result_score['WaveLength'] = col\n",
    "    result_score['score']= score\n",
    "    result_scores.append(result_score)\n",
    "\n",
    "fd_result_score = pd.DataFrame(result_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fd_result_score.to_excel('full_data_random_forest_score.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Fitting the classifier to the training set\")\n",
    "t0 = time()\n",
    "param_grid = {'n_estimators':[50,100,150],'max_depth': range(1,20), 'criterion':['gini','entropy']}\n",
    "print(\"Set Grid parameters\")\n",
    "clf = GridSearchCV(\n",
    "    RandomForestClassifier(), param_grid, cv=10)\n",
    "print(\"Start to fit\")\n",
    "clf = clf.fit(x_train, y_train)\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "print(\"Best estimator found by grid search:\")\n",
    "print(clf.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = clf.score(x_test, y_test)\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gaussian process classification (GPC) based on Laplace approximation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### this method is very slow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = full_data['label'].tolist()\n",
    "label = np.asarray(label).reshape(-1,)\n",
    "cols = full_data.columns.tolist()\n",
    "cols = cols[1:]\n",
    "x = full_data[cols[10]].tolist()\n",
    "x = np.asarray(x).reshape(-1,1)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, label, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = 1.0 * RBF(1.0)\n",
    "clf = GaussianProcessClassifier(kernel=kernel, random_state=46)\n",
    "clf.fit(x_train, y_train)\n",
    "clf.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = full_data['label'].tolist()\n",
    "label = np.asarray(label).reshape(-1,)\n",
    "cols = full_data.columns.tolist()\n",
    "cols = cols[1:]\n",
    "x = full_data[cols[10]].tolist()\n",
    "x = np.asarray(x).reshape(-1,1)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, label, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = AdaBoostClassifier(n_estimators=100, random_state=46)\n",
    "clf.fit(x_train, y_train)\n",
    "clf.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = full_data['label'].tolist()\n",
    "label = np.asarray(label).reshape(-1,)\n",
    "cols = full_data.columns.tolist()\n",
    "cols = cols[1:]\n",
    "x = full_data[cols[10]].tolist()\n",
    "x = np.asarray(x).reshape(-1,1)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, label, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = KNeighborsClassifier(n_neighbors=3)\n",
    "clf.fit(x_train, y_train)\n",
    "clf.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gaussian Naive Bayes (GaussianNB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = full_data['label'].tolist()\n",
    "label = np.asarray(label).reshape(-1,)\n",
    "cols = full_data.columns.tolist()\n",
    "cols = cols[1:]\n",
    "x = full_data[cols[10]].tolist()\n",
    "x = np.asarray(x).reshape(-1,1)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, label, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GaussianNB()\n",
    "clf.fit(x_train, y_train)\n",
    "clf.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quadratic Discriminant Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = full_data['label'].tolist()\n",
    "label = np.asarray(label).reshape(-1,)\n",
    "cols = full_data.columns.tolist()\n",
    "cols = cols[1:]\n",
    "x = full_data[cols[10]].tolist()\n",
    "x = np.asarray(x).reshape(-1,1)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, label, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = QuadraticDiscriminantAnalysis()\n",
    "clf.fit(x_train, y_train)\n",
    "clf.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classify data with label from 0-7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data = pd.read_excel(\"full_data_with_class.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = full_data['label'].tolist()\n",
    "label = np.asarray(label).reshape(-1,)\n",
    "cols = full_data.columns.tolist()\n",
    "cols = cols[1:]\n",
    "x = full_data[cols[10]].tolist()\n",
    "x = np.asarray(x).reshape(-1,1)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, label, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier()\n",
    "clf.fit(x_train, y_train)\n",
    "clf.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Fitting the classifier to the training set\")\n",
    "t0 = time()\n",
    "param_grid = {'n_estimators':[50,100,150],'max_depth': range(1,20), 'criterion':['gini','entropy']}\n",
    "print(\"Set Grid parameters\")\n",
    "clf = GridSearchCV(\n",
    "    RandomForestClassifier(), param_grid, cv=10)\n",
    "print(\"Start to fit\")\n",
    "clf = clf.fit(x_train, y_train)\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "print(\"Best estimator found by grid search:\")\n",
    "print(clf.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_scores = []\n",
    "for col in cols:\n",
    "    # Xarray-like of shape (n_samples, n_features) Training vector, \n",
    "    # where n_samples is the number of samples and n_features is the number of features.\n",
    "    x = full_data[col].tolist()\n",
    "    x = np.asarray(x).reshape(-1,1)\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, label, test_size=0.2, random_state=42)\n",
    "\n",
    "    clf = RandomForestClassifier(n_estimators=150,criterion='entropy', max_depth=19)\n",
    "    clf.fit(x_train, y_train)\n",
    "    score = clf.score(x_test, y_test)\n",
    "\n",
    "    result_score = dict()\n",
    "    result_score['WaveLength'] = col\n",
    "    result_score['score']= score\n",
    "    result_scores.append(result_score)\n",
    "\n",
    "fd_result_score = pd.DataFrame(result_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fd_result_score.to_excel('full_data_with_class_random_forest_score.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classify only disease data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data = pd.read_excel(\"full_disease_data.xlsx\")\n",
    "full_data.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = full_data['label'].tolist()\n",
    "label = np.asarray(label).reshape(-1,)\n",
    "cols = full_data.columns.tolist()\n",
    "cols = cols[1:]\n",
    "x = full_data[cols[10]].tolist()\n",
    "x = np.asarray(x).reshape(-1,1)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, label, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier()\n",
    "clf.fit(x_train, y_train)\n",
    "clf.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Fitting the classifier to the training set\")\n",
    "t0 = time()\n",
    "param_grid = {'n_estimators':[50,100,150],'max_depth': range(1,20), 'criterion':['gini','entropy']}\n",
    "print(\"Set Grid parameters\")\n",
    "clf = GridSearchCV(\n",
    "    RandomForestClassifier(), param_grid, cv=10)\n",
    "print(\"Start to fit\")\n",
    "clf = clf.fit(x_train, y_train)\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "print(\"Best estimator found by grid search:\")\n",
    "print(clf.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The result of only disease data isn't good, so try to other algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = full_data['label'].tolist()\n",
    "label = np.asarray(label).reshape(-1,)\n",
    "\n",
    "cols = full_data.columns.tolist()\n",
    "cols = cols[1:]\n",
    "x = full_data[cols[10]].tolist()\n",
    "x = np.asarray(x).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #############################################################################\n",
    "# Train a SVM classification model\n",
    "\n",
    "print(\"Fitting the classifier to the training set\")\n",
    "t0 = time()\n",
    "param_grid = {'C': [1e2,5e2,1e3, 5e3, 1e4],\n",
    "              'gamma': [0.001, 0.005, 0.01,0.05,0.1,0.2]}\n",
    "print(\"Set Grid parameters\")\n",
    "clf = GridSearchCV(\n",
    "    SVC(kernel='rbf', class_weight='balanced'), param_grid, cv=5)\n",
    "print(\"Start to fit\")\n",
    "clf = clf.fit(x_train, y_train)\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "print(\"Best estimator found by grid search:\")\n",
    "print(clf.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = full_data['label'].tolist()\n",
    "label = np.asarray(label).reshape(-1,1)\n",
    "cols = full_data.columns.tolist()\n",
    "cols = cols[1:]\n",
    "x = full_data[cols[10]].tolist()\n",
    "x = np.asarray(x).reshape(-1,1)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, label, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Fitting the classifier to the training set\")\n",
    "t0 = time()\n",
    "param_grid = {'max_depth': range(1,20), 'criterion':['gini','entropy']}\n",
    "print(\"Set Grid parameters\")\n",
    "clf = GridSearchCV(\n",
    "    DecisionTreeClassifier(), param_grid, cv=5)\n",
    "print(\"Start to fit\")\n",
    "clf = clf.fit(x_train, y_train)\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "print(\"Best estimator found by grid search:\")\n",
    "print(clf.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gaussian process classification (GPC) based on Laplace approximation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = full_data['label'].tolist()\n",
    "label = np.asarray(label).reshape(-1,)\n",
    "cols = full_data.columns.tolist()\n",
    "cols = cols[1:]\n",
    "x = full_data[cols[10]].tolist()\n",
    "x = np.asarray(x).reshape(-1,1)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, label, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = 1.0 * RBF(1.0)\n",
    "clf = GaussianProcessClassifier(kernel=kernel, random_state=46)\n",
    "clf.fit(x_train, y_train)\n",
    "clf.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = full_data['label'].tolist()\n",
    "label = np.asarray(label).reshape(-1,)\n",
    "cols = full_data.columns.tolist()\n",
    "cols = cols[1:]\n",
    "x = full_data[cols[10]].tolist()\n",
    "x = np.asarray(x).reshape(-1,1)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, label, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = AdaBoostClassifier(n_estimators=100, random_state=46)\n",
    "clf.fit(x_train, y_train)\n",
    "clf.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = full_data['label'].tolist()\n",
    "label = np.asarray(label).reshape(-1,)\n",
    "cols = full_data.columns.tolist()\n",
    "cols = cols[1:]\n",
    "x = full_data[cols[10]].tolist()\n",
    "x = np.asarray(x).reshape(-1,1)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, label, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = KNeighborsClassifier(n_neighbors=3)\n",
    "clf.fit(x_train, y_train)\n",
    "clf.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gaussian Naive Bayes (GaussianNB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = full_data['label'].tolist()\n",
    "label = np.asarray(label).reshape(-1,)\n",
    "cols = full_data.columns.tolist()\n",
    "cols = cols[1:]\n",
    "x = full_data[cols[10]].tolist()\n",
    "x = np.asarray(x).reshape(-1,1)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, label, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GaussianNB()\n",
    "clf.fit(x_train, y_train)\n",
    "clf.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quadratic Discriminant Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = full_data['label'].tolist()\n",
    "label = np.asarray(label).reshape(-1,)\n",
    "cols = full_data.columns.tolist()\n",
    "cols = cols[1:]\n",
    "x = full_data[cols[10]].tolist()\n",
    "x = np.asarray(x).reshape(-1,1)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, label, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = QuadraticDiscriminantAnalysis()\n",
    "clf.fit(x_train, y_train)\n",
    "clf.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try for single disease file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data = pd.read_excel(\"sc16_29_new.xlsx\")\n",
    "full_data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "health_rows = full_data[full_data['label'] == 0]\n",
    "disease_rows = full_data[full_data['label'] != 0]\n",
    "length = disease_rows['label'].count()\n",
    "selected_rows = health_rows.sample(length)\n",
    "new_pd = selected_rows.append(disease_rows, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = new_pd['label'].tolist()\n",
    "label = np.asarray(label).reshape(-1,)\n",
    "cols = new_pd.columns.tolist()\n",
    "cols = cols[1:]\n",
    "x = new_pd[cols[10]].tolist()\n",
    "x = np.asarray(x).reshape(-1,1)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, label, test_size=0.3, random_state=99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Fitting the classifier to the training set\")\n",
    "t0 = time()\n",
    "param_grid = {'n_estimators':[50,100,150],'max_depth': range(1,20), 'criterion':['gini','entropy']}\n",
    "print(\"Set Grid parameters\")\n",
    "clf = GridSearchCV(\n",
    "    RandomForestClassifier(), param_grid, cv=10)\n",
    "print(\"Start to fit\")\n",
    "clf = clf.fit(x_train, y_train)\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "print(\"Best estimator found by grid search:\")\n",
    "print(clf.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = full_data['label'].tolist()\n",
    "label = np.asarray(label).reshape(-1,)\n",
    "cols = full_data.columns.tolist()\n",
    "cols = cols[1:]\n",
    "x = full_data[cols[10]].tolist()\n",
    "x = np.asarray(x).reshape(-1,1)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, label, test_size=0.2, random_state=46)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #############################################################################\n",
    "# Train a SVM classification model\n",
    "\n",
    "print(\"Fitting the classifier to the training set\")\n",
    "t0 = time()\n",
    "param_grid = {'C': [1e2,5e2,1e3, 5e3, 1e4],\n",
    "              'gamma': [0.001, 0.005, 0.01,0.05,0.1,0.2]}\n",
    "print(\"Set Grid parameters\")\n",
    "clf = GridSearchCV(\n",
    "    SVC(kernel='rbf', class_weight='balanced'), param_grid, cv=10)\n",
    "print(\"Start to fit\")\n",
    "clf = clf.fit(x_train, y_train)\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "print(\"Best estimator found by grid search:\")\n",
    "print(clf.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = full_data['label'].tolist()\n",
    "label = np.asarray(label).reshape(-1,1)\n",
    "cols = full_data.columns.tolist()\n",
    "cols = cols[1:]\n",
    "x = full_data[cols[10]].tolist()\n",
    "x = np.asarray(x).reshape(-1,1)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, label, test_size=0.2, random_state=88)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Fitting the classifier to the training set\")\n",
    "t0 = time()\n",
    "param_grid = {'max_depth': range(1,20), 'criterion':['gini','entropy']}\n",
    "print(\"Set Grid parameters\")\n",
    "clf = GridSearchCV(\n",
    "    DecisionTreeClassifier(), param_grid, cv=5)\n",
    "print(\"Start to fit\")\n",
    "clf = clf.fit(x_train, y_train)\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "print(\"Best estimator found by grid search:\")\n",
    "print(clf.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gaussian process classification (GPC) based on Laplace approximation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = full_data['label'].tolist()\n",
    "label = np.asarray(label).reshape(-1,)\n",
    "cols = full_data.columns.tolist()\n",
    "cols = cols[1:]\n",
    "x = full_data[cols[10]].tolist()\n",
    "x = np.asarray(x).reshape(-1,1)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, label, test_size=0.2, random_state=55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = 1.0 * RBF(1.0)\n",
    "clf = GaussianProcessClassifier(kernel=kernel, random_state=46)\n",
    "clf.fit(x_train, y_train)\n",
    "clf.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = full_data['label'].tolist()\n",
    "label = np.asarray(label).reshape(-1,)\n",
    "cols = full_data.columns.tolist()\n",
    "cols = cols[1:]\n",
    "x = full_data[cols[10]].tolist()\n",
    "x = np.asarray(x).reshape(-1,1)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, label, test_size=0.2, random_state=66)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = AdaBoostClassifier(n_estimators=100, random_state=46)\n",
    "clf.fit(x_train, y_train)\n",
    "clf.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = full_data['label'].tolist()\n",
    "label = np.asarray(label).reshape(-1,)\n",
    "cols = full_data.columns.tolist()\n",
    "cols = cols[1:]\n",
    "x = full_data[cols[10]].tolist()\n",
    "x = np.asarray(x).reshape(-1,1)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, label, test_size=0.2, random_state=66)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = KNeighborsClassifier(n_neighbors=3)\n",
    "clf.fit(x_train, y_train)\n",
    "clf.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gaussian Naive Bayes (GaussianNB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = full_data['label'].tolist()\n",
    "label = np.asarray(label).reshape(-1,)\n",
    "cols = full_data.columns.tolist()\n",
    "cols = cols[1:]\n",
    "x = full_data[cols[10]].tolist()\n",
    "x = np.asarray(x).reshape(-1,1)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, label, test_size=0.2, random_state=33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GaussianNB()\n",
    "clf.fit(x_train, y_train)\n",
    "clf.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quadratic Discriminant Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = full_data['label'].tolist()\n",
    "label = np.asarray(label).reshape(-1,)\n",
    "cols = full_data.columns.tolist()\n",
    "cols = cols[1:]\n",
    "x = full_data[cols[10]].tolist()\n",
    "x = np.asarray(x).reshape(-1,1)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, label, test_size=0.2, random_state=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = QuadraticDiscriminantAnalysis()\n",
    "clf.fit(x_train, y_train)\n",
    "clf.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note, seems the score are good enough.The reason is maybe each file only has two class: 0 and other value.\n",
    "Another thing is when I split train and test dataset, the value of <b>random_state</b> changed, the final score will changed. \n",
    "The reason is maybe dataset isn't large enough."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use Ada boost for each file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = ['sc1_new.xlsx', 'sc2_4_new.xlsx', 'sc5_7_new.xlsx', 'sc8_15_new.xlsx','sc16_29_new.xlsx','sc30_49_new.xlsx','sc50_70_new.xlsx']\n",
    "#file_list = ['sc50_70_new.xlsx']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in file_list:\n",
    "    full_data = pd.read_excel(file)\n",
    "    health_rows = full_data[full_data['label'] == 0]\n",
    "    disease_rows = full_data[full_data['label'] != 0]\n",
    "    length = disease_rows['label'].count()\n",
    "    selected_rows = health_rows.sample(length)\n",
    "    new_pd = selected_rows.append(disease_rows, ignore_index=True)\n",
    "    label = new_pd['label'].tolist()\n",
    "    label = np.asarray(label).reshape(-1,)\n",
    "    \n",
    "    cols = new_pd.columns.tolist()\n",
    "    cols = cols[1:]\n",
    "    \n",
    "    # Process each wavelenth\n",
    "    result_scores = []\n",
    "    for col in cols:\n",
    "        x = full_data[col].tolist()\n",
    "        x = np.asarray(x).reshape(-1,1)\n",
    "        x_train, x_test, y_train, y_test = train_test_split(x, label, test_size=0.3, random_state=66)\n",
    "        \n",
    "        #t0 = time()\n",
    "        param_grid = {'C': [1e2,5e2,1e3, 5e3, 1e4],\n",
    "                      'gamma': [0.001, 0.005, 0.01,0.05,0.1,0.2]}\n",
    "        #print(\"Set Grid parameters\")\n",
    "        clf = GridSearchCV(\n",
    "            SVC(kernel='rbf', class_weight='balanced'), param_grid, cv=10)\n",
    "        #print(\"Start to fit\")\n",
    "        clf = clf.fit(x_train, y_train)\n",
    "        #print(clf.best_estimator_)\n",
    "        \n",
    "        #clf = AdaBoostClassifier(n_estimators=100, random_state=46)\n",
    "        #clf.fit(x_train, y_train)\n",
    "        score = clf.score(x_test, y_test)\n",
    "        \n",
    "        result_score = dict()\n",
    "        result_score['WaveLength'] = col\n",
    "        result_score['score']= score\n",
    "        result_score['best_parms'] = clf.best_estimator_\n",
    "        result_scores.append(result_score)\n",
    "        \n",
    "    new_file = file.split('.')[0] + '_svm_result.xlsx'\n",
    "    result_pd = pd.DataFrame(result_scores)\n",
    "    result_pd.to_excel(new_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process SC 50-70 new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>394.6</th>\n",
       "      <th>396.7</th>\n",
       "      <th>398.7</th>\n",
       "      <th>400.8</th>\n",
       "      <th>402.8</th>\n",
       "      <th>404.9</th>\n",
       "      <th>406.9</th>\n",
       "      <th>409</th>\n",
       "      <th>411</th>\n",
       "      <th>...</th>\n",
       "      <th>866.7</th>\n",
       "      <th>868.8</th>\n",
       "      <th>870.9</th>\n",
       "      <th>872.9</th>\n",
       "      <th>875</th>\n",
       "      <th>877</th>\n",
       "      <th>879.1</th>\n",
       "      <th>881.1</th>\n",
       "      <th>883.2</th>\n",
       "      <th>885.2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.04827</td>\n",
       "      <td>0.04468</td>\n",
       "      <td>0.04008</td>\n",
       "      <td>0.03521</td>\n",
       "      <td>0.03030</td>\n",
       "      <td>0.02578</td>\n",
       "      <td>0.02212</td>\n",
       "      <td>0.01985</td>\n",
       "      <td>0.01826</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3162</td>\n",
       "      <td>0.3168</td>\n",
       "      <td>0.3175</td>\n",
       "      <td>0.3180</td>\n",
       "      <td>0.3184</td>\n",
       "      <td>0.3187</td>\n",
       "      <td>0.3190</td>\n",
       "      <td>0.3194</td>\n",
       "      <td>0.3195</td>\n",
       "      <td>0.3194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.05322</td>\n",
       "      <td>0.04898</td>\n",
       "      <td>0.04387</td>\n",
       "      <td>0.03805</td>\n",
       "      <td>0.03224</td>\n",
       "      <td>0.02683</td>\n",
       "      <td>0.02242</td>\n",
       "      <td>0.01950</td>\n",
       "      <td>0.01754</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3379</td>\n",
       "      <td>0.3388</td>\n",
       "      <td>0.3393</td>\n",
       "      <td>0.3402</td>\n",
       "      <td>0.3408</td>\n",
       "      <td>0.3412</td>\n",
       "      <td>0.3415</td>\n",
       "      <td>0.3417</td>\n",
       "      <td>0.3419</td>\n",
       "      <td>0.3416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.04710</td>\n",
       "      <td>0.04375</td>\n",
       "      <td>0.03963</td>\n",
       "      <td>0.03504</td>\n",
       "      <td>0.03022</td>\n",
       "      <td>0.02590</td>\n",
       "      <td>0.02229</td>\n",
       "      <td>0.01998</td>\n",
       "      <td>0.01833</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3627</td>\n",
       "      <td>0.3634</td>\n",
       "      <td>0.3638</td>\n",
       "      <td>0.3643</td>\n",
       "      <td>0.3648</td>\n",
       "      <td>0.3651</td>\n",
       "      <td>0.3651</td>\n",
       "      <td>0.3649</td>\n",
       "      <td>0.3651</td>\n",
       "      <td>0.3648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.04965</td>\n",
       "      <td>0.04648</td>\n",
       "      <td>0.04230</td>\n",
       "      <td>0.03775</td>\n",
       "      <td>0.03321</td>\n",
       "      <td>0.02890</td>\n",
       "      <td>0.02520</td>\n",
       "      <td>0.02265</td>\n",
       "      <td>0.02040</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3373</td>\n",
       "      <td>0.3383</td>\n",
       "      <td>0.3390</td>\n",
       "      <td>0.3399</td>\n",
       "      <td>0.3406</td>\n",
       "      <td>0.3412</td>\n",
       "      <td>0.3419</td>\n",
       "      <td>0.3423</td>\n",
       "      <td>0.3429</td>\n",
       "      <td>0.3432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.04562</td>\n",
       "      <td>0.04221</td>\n",
       "      <td>0.03784</td>\n",
       "      <td>0.03332</td>\n",
       "      <td>0.02895</td>\n",
       "      <td>0.02493</td>\n",
       "      <td>0.02176</td>\n",
       "      <td>0.02012</td>\n",
       "      <td>0.01829</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2413</td>\n",
       "      <td>0.2420</td>\n",
       "      <td>0.2431</td>\n",
       "      <td>0.2438</td>\n",
       "      <td>0.2444</td>\n",
       "      <td>0.2452</td>\n",
       "      <td>0.2458</td>\n",
       "      <td>0.2463</td>\n",
       "      <td>0.2465</td>\n",
       "      <td>0.2471</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 241 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label    394.6    396.7    398.7    400.8    402.8    404.9    406.9  \\\n",
       "0      0  0.04827  0.04468  0.04008  0.03521  0.03030  0.02578  0.02212   \n",
       "1      0  0.05322  0.04898  0.04387  0.03805  0.03224  0.02683  0.02242   \n",
       "2      0  0.04710  0.04375  0.03963  0.03504  0.03022  0.02590  0.02229   \n",
       "3      0  0.04965  0.04648  0.04230  0.03775  0.03321  0.02890  0.02520   \n",
       "4      0  0.04562  0.04221  0.03784  0.03332  0.02895  0.02493  0.02176   \n",
       "\n",
       "       409      411   ...     866.7   868.8   870.9   872.9     875     877  \\\n",
       "0  0.01985  0.01826   ...    0.3162  0.3168  0.3175  0.3180  0.3184  0.3187   \n",
       "1  0.01950  0.01754   ...    0.3379  0.3388  0.3393  0.3402  0.3408  0.3412   \n",
       "2  0.01998  0.01833   ...    0.3627  0.3634  0.3638  0.3643  0.3648  0.3651   \n",
       "3  0.02265  0.02040   ...    0.3373  0.3383  0.3390  0.3399  0.3406  0.3412   \n",
       "4  0.02012  0.01829   ...    0.2413  0.2420  0.2431  0.2438  0.2444  0.2452   \n",
       "\n",
       "    879.1   881.1   883.2   885.2  \n",
       "0  0.3190  0.3194  0.3195  0.3194  \n",
       "1  0.3415  0.3417  0.3419  0.3416  \n",
       "2  0.3651  0.3649  0.3651  0.3648  \n",
       "3  0.3419  0.3423  0.3429  0.3432  \n",
       "4  0.2458  0.2463  0.2465  0.2471  \n",
       "\n",
       "[5 rows x 241 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = \"More H VS. SC 50-70.xlsx\"\n",
    "full_data = pd.read_excel(file)\n",
    "full_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = full_data['label'].tolist()\n",
    "label = np.asarray(label).reshape(-1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = full_data.columns.tolist()\n",
    "cols = cols[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = full_data.iloc[:,1:]\n",
    "x = x[cols[100]].tolist()\n",
    "x = np.asarray(x).reshape(-1,1)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, label, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting the classifier to the training set\n",
      "Set Grid parameters\n",
      "Start to fit\n",
      "done in 15.876s\n",
      "Best estimator found by grid search:\n",
      "SVC(C=1000.0, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma=0.2, kernel='rbf',\n",
      "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Anaconda3\\envs\\py2\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# #############################################################################\n",
    "# Train a SVM classification model\n",
    "\n",
    "print(\"Fitting the classifier to the training set\")\n",
    "t0 = time()\n",
    "param_grid = {'kernel':['rbf','sigmoid'],'C': [1e2,5e2,1e3, 5e3, 1e4],\n",
    "              'gamma': [0.001, 0.005, 0.01,0.05,0.1,0.2]}\n",
    "print(\"Set Grid parameters\")\n",
    "clf = GridSearchCV(\n",
    "    SVC(class_weight='balanced',probability=True), param_grid, cv=10)\n",
    "print(\"Start to fit\")\n",
    "clf = clf.fit(x_train, y_train)\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "print(\"Best estimator found by grid search:\")\n",
    "print(clf.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6972477064220184"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "health_rows = full_data[full_data['label'] == 0]\n",
    "disease_rows = full_data[full_data['label'] != 0]\n",
    "length = disease_rows['label'].count()\n",
    "selected_rows = health_rows.sample(length)\n",
    "new_pd = selected_rows.append(disease_rows, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "338"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting the classifier to the training set\n",
      "Set Grid parameters\n",
      "Start to fit\n",
      "done in 110.443s\n",
      "Best estimator found by grid search:\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=3, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=150, n_jobs=None,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Anaconda3\\envs\\py2\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "print(\"Fitting the classifier to the training set\")\n",
    "t0 = time()\n",
    "param_grid = {'n_estimators':[50,100,150],'max_depth': range(1,20), 'criterion':['gini','entropy']}\n",
    "print(\"Set Grid parameters\")\n",
    "clf = GridSearchCV(\n",
    "    RandomForestClassifier(), param_grid, cv=10)\n",
    "print(\"Start to fit\")\n",
    "clf = clf.fit(x_train, y_train)\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "print(\"Best estimator found by grid search:\")\n",
    "print(clf.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7201834862385321"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian Naive Bayes (GaussianNB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting the classifier to the training set\n",
      "Set Grid parameters\n",
      "Start to fit\n",
      "done in 0.018s\n",
      "Best estimator found by grid search:\n",
      "GaussianNB(priors=None, var_smoothing=1e-09)\n"
     ]
    }
   ],
   "source": [
    "print(\"Fitting the classifier to the training set\")\n",
    "t0 = time()\n",
    "param_grid = {}\n",
    "print(\"Set Grid parameters\")\n",
    "clf = GridSearchCV(\n",
    "    GaussianNB(), param_grid, cv=10)\n",
    "print(\"Start to fit\")\n",
    "clf = clf.fit(x_train, y_train)\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "print(\"Best estimator found by grid search:\")\n",
    "print(clf.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6788990825688074"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = KNeighborsClassifier(n_neighbors=3)\n",
    "clf.fit(x_train, y_train)\n",
    "clf.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting the classifier to the training set\n",
      "Set Grid parameters\n",
      "Start to fit\n",
      "done in 0.600s\n",
      "Best estimator found by grid search:\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=None, n_neighbors=19, p=2,\n",
      "           weights='uniform')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Anaconda3\\envs\\py2\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "print(\"Fitting the classifier to the training set\")\n",
    "t0 = time()\n",
    "param_grid = {'n_neighbors':range(1,20)}\n",
    "print(\"Set Grid parameters\")\n",
    "clf = GridSearchCV(\n",
    "    KNeighborsClassifier(), param_grid, cv=10)\n",
    "print(\"Start to fit\")\n",
    "clf = clf.fit(x_train, y_train)\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "print(\"Best estimator found by grid search:\")\n",
    "print(clf.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7110091743119266"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>394.6</th>\n",
       "      <th>396.7</th>\n",
       "      <th>398.7</th>\n",
       "      <th>400.8</th>\n",
       "      <th>402.8</th>\n",
       "      <th>404.9</th>\n",
       "      <th>406.9</th>\n",
       "      <th>409.0</th>\n",
       "      <th>411.0</th>\n",
       "      <th>413.1</th>\n",
       "      <th>...</th>\n",
       "      <th>866.7</th>\n",
       "      <th>868.8</th>\n",
       "      <th>870.9</th>\n",
       "      <th>872.9</th>\n",
       "      <th>875.0</th>\n",
       "      <th>877.0</th>\n",
       "      <th>879.1</th>\n",
       "      <th>881.1</th>\n",
       "      <th>883.2</th>\n",
       "      <th>885.2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.04827</td>\n",
       "      <td>0.04468</td>\n",
       "      <td>0.04008</td>\n",
       "      <td>0.03521</td>\n",
       "      <td>0.03030</td>\n",
       "      <td>0.02578</td>\n",
       "      <td>0.02212</td>\n",
       "      <td>0.01985</td>\n",
       "      <td>0.01826</td>\n",
       "      <td>0.01732</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3162</td>\n",
       "      <td>0.3168</td>\n",
       "      <td>0.3175</td>\n",
       "      <td>0.3180</td>\n",
       "      <td>0.3184</td>\n",
       "      <td>0.3187</td>\n",
       "      <td>0.3190</td>\n",
       "      <td>0.3194</td>\n",
       "      <td>0.3195</td>\n",
       "      <td>0.3194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.05322</td>\n",
       "      <td>0.04898</td>\n",
       "      <td>0.04387</td>\n",
       "      <td>0.03805</td>\n",
       "      <td>0.03224</td>\n",
       "      <td>0.02683</td>\n",
       "      <td>0.02242</td>\n",
       "      <td>0.01950</td>\n",
       "      <td>0.01754</td>\n",
       "      <td>0.01761</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3379</td>\n",
       "      <td>0.3388</td>\n",
       "      <td>0.3393</td>\n",
       "      <td>0.3402</td>\n",
       "      <td>0.3408</td>\n",
       "      <td>0.3412</td>\n",
       "      <td>0.3415</td>\n",
       "      <td>0.3417</td>\n",
       "      <td>0.3419</td>\n",
       "      <td>0.3416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.04710</td>\n",
       "      <td>0.04375</td>\n",
       "      <td>0.03963</td>\n",
       "      <td>0.03504</td>\n",
       "      <td>0.03022</td>\n",
       "      <td>0.02590</td>\n",
       "      <td>0.02229</td>\n",
       "      <td>0.01998</td>\n",
       "      <td>0.01833</td>\n",
       "      <td>0.01790</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3627</td>\n",
       "      <td>0.3634</td>\n",
       "      <td>0.3638</td>\n",
       "      <td>0.3643</td>\n",
       "      <td>0.3648</td>\n",
       "      <td>0.3651</td>\n",
       "      <td>0.3651</td>\n",
       "      <td>0.3649</td>\n",
       "      <td>0.3651</td>\n",
       "      <td>0.3648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.04965</td>\n",
       "      <td>0.04648</td>\n",
       "      <td>0.04230</td>\n",
       "      <td>0.03775</td>\n",
       "      <td>0.03321</td>\n",
       "      <td>0.02890</td>\n",
       "      <td>0.02520</td>\n",
       "      <td>0.02265</td>\n",
       "      <td>0.02040</td>\n",
       "      <td>0.02007</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3373</td>\n",
       "      <td>0.3383</td>\n",
       "      <td>0.3390</td>\n",
       "      <td>0.3399</td>\n",
       "      <td>0.3406</td>\n",
       "      <td>0.3412</td>\n",
       "      <td>0.3419</td>\n",
       "      <td>0.3423</td>\n",
       "      <td>0.3429</td>\n",
       "      <td>0.3432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.04562</td>\n",
       "      <td>0.04221</td>\n",
       "      <td>0.03784</td>\n",
       "      <td>0.03332</td>\n",
       "      <td>0.02895</td>\n",
       "      <td>0.02493</td>\n",
       "      <td>0.02176</td>\n",
       "      <td>0.02012</td>\n",
       "      <td>0.01829</td>\n",
       "      <td>0.01795</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2413</td>\n",
       "      <td>0.2420</td>\n",
       "      <td>0.2431</td>\n",
       "      <td>0.2438</td>\n",
       "      <td>0.2444</td>\n",
       "      <td>0.2452</td>\n",
       "      <td>0.2458</td>\n",
       "      <td>0.2463</td>\n",
       "      <td>0.2465</td>\n",
       "      <td>0.2471</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 240 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     394.6    396.7    398.7    400.8    402.8    404.9    406.9    409.0  \\\n",
       "0  0.04827  0.04468  0.04008  0.03521  0.03030  0.02578  0.02212  0.01985   \n",
       "1  0.05322  0.04898  0.04387  0.03805  0.03224  0.02683  0.02242  0.01950   \n",
       "2  0.04710  0.04375  0.03963  0.03504  0.03022  0.02590  0.02229  0.01998   \n",
       "3  0.04965  0.04648  0.04230  0.03775  0.03321  0.02890  0.02520  0.02265   \n",
       "4  0.04562  0.04221  0.03784  0.03332  0.02895  0.02493  0.02176  0.02012   \n",
       "\n",
       "     411.0    413.1   ...     866.7   868.8   870.9   872.9   875.0   877.0  \\\n",
       "0  0.01826  0.01732   ...    0.3162  0.3168  0.3175  0.3180  0.3184  0.3187   \n",
       "1  0.01754  0.01761   ...    0.3379  0.3388  0.3393  0.3402  0.3408  0.3412   \n",
       "2  0.01833  0.01790   ...    0.3627  0.3634  0.3638  0.3643  0.3648  0.3651   \n",
       "3  0.02040  0.02007   ...    0.3373  0.3383  0.3390  0.3399  0.3406  0.3412   \n",
       "4  0.01829  0.01795   ...    0.2413  0.2420  0.2431  0.2438  0.2444  0.2452   \n",
       "\n",
       "    879.1   881.1   883.2   885.2  \n",
       "0  0.3190  0.3194  0.3195  0.3194  \n",
       "1  0.3415  0.3417  0.3419  0.3416  \n",
       "2  0.3651  0.3649  0.3651  0.3648  \n",
       "3  0.3419  0.3423  0.3429  0.3432  \n",
       "4  0.2458  0.2463  0.2465  0.2471  \n",
       "\n",
       "[5 rows x 240 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_tmp = full_data.drop(['label'],axis=1)\n",
    "_tmp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "620.4    0.995917\n",
       "622.5    0.996764\n",
       "624.5    0.997391\n",
       "626.6    0.997862\n",
       "628.6    0.998318\n",
       "630.7    0.998706\n",
       "632.7    0.999060\n",
       "634.8    0.999387\n",
       "636.8    0.999680\n",
       "638.9    0.999905\n",
       "640.9    1.000000\n",
       "643      0.999887\n",
       "645      0.999571\n",
       "647.1    0.999045\n",
       "649.1    0.998381\n",
       "651.2    0.997638\n",
       "653.3    0.996808\n",
       "655.3    0.995870\n",
       "657.4    0.994779\n",
       "659.4    0.993491\n",
       "Name: 640.9, dtype: float64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr = _tmp.corr()\n",
    "corr.iloc[110:130,120]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "row = corr.iloc[1,:].tolist()\n",
    "row = np.asarray(row).reshape(-1,1)\n",
    "kmeans = KMeans(n_clusters=20, random_state=0).fit(row)\n",
    "label_1 = kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = corr.iloc[10,:].tolist()\n",
    "row = np.asarray(row).reshape(-1,1)\n",
    "kmeans = KMeans(n_clusters=20, random_state=0).fit(row)\n",
    "label_10 = kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [636.8,\n",
       "  638.9,\n",
       "  640.9,\n",
       "  643,\n",
       "  645,\n",
       "  647.1,\n",
       "  649.1,\n",
       "  651.2,\n",
       "  653.3,\n",
       "  655.3,\n",
       "  657.4,\n",
       "  698.4,\n",
       "  700.5,\n",
       "  731.3],\n",
       " 1: [474.7,\n",
       "  476.7,\n",
       "  478.8,\n",
       "  480.8,\n",
       "  482.9,\n",
       "  484.9,\n",
       "  487,\n",
       "  489,\n",
       "  491.1,\n",
       "  493.1,\n",
       "  495.2,\n",
       "  497.2,\n",
       "  499.3,\n",
       "  501.3,\n",
       "  503.4,\n",
       "  505.5,\n",
       "  507.5,\n",
       "  509.6,\n",
       "  511.6,\n",
       "  513.7,\n",
       "  515.7,\n",
       "  517.8,\n",
       "  519.8,\n",
       "  521.9,\n",
       "  523.9,\n",
       "  526,\n",
       "  528],\n",
       " 2: [751.8,\n",
       "  753.8,\n",
       "  755.9,\n",
       "  757.9,\n",
       "  760,\n",
       "  762.1,\n",
       "  764.1,\n",
       "  766.2,\n",
       "  813.4,\n",
       "  815.4,\n",
       "  817.5,\n",
       "  819.5,\n",
       "  821.6,\n",
       "  823.6,\n",
       "  825.7,\n",
       "  827.7,\n",
       "  829.8,\n",
       "  831.8,\n",
       "  833.9,\n",
       "  836,\n",
       "  838,\n",
       "  840.1,\n",
       "  842.1,\n",
       "  844.2,\n",
       "  846.2,\n",
       "  848.3,\n",
       "  850.3,\n",
       "  852.4,\n",
       "  854.4,\n",
       "  856.5,\n",
       "  858.5,\n",
       "  860.6,\n",
       "  862.6,\n",
       "  864.7,\n",
       "  866.7],\n",
       " 3: [400.8],\n",
       " 4: [406.9,\n",
       "  431.6,\n",
       "  433.6,\n",
       "  435.7,\n",
       "  437.7,\n",
       "  439.8,\n",
       "  441.8,\n",
       "  443.9,\n",
       "  445.9,\n",
       "  448,\n",
       "  450,\n",
       "  452.1],\n",
       " 5: [608.1, 610.1, 612.2, 614.2, 616.3, 706.6, 708.7, 725.1],\n",
       " 6: [548.6,\n",
       "  550.6,\n",
       "  552.7,\n",
       "  554.7,\n",
       "  556.8,\n",
       "  558.8,\n",
       "  560.9,\n",
       "  562.9,\n",
       "  565,\n",
       "  567,\n",
       "  569.1,\n",
       "  571.1,\n",
       "  573.2],\n",
       " 7: [659.4,\n",
       "  661.5,\n",
       "  663.5,\n",
       "  665.6,\n",
       "  667.6,\n",
       "  669.7,\n",
       "  671.7,\n",
       "  673.8,\n",
       "  675.8,\n",
       "  677.9,\n",
       "  679.9,\n",
       "  682,\n",
       "  684,\n",
       "  686.1,\n",
       "  688.1,\n",
       "  690.2,\n",
       "  692.3,\n",
       "  694.3,\n",
       "  696.4,\n",
       "  733.3,\n",
       "  735.4,\n",
       "  737.4],\n",
       " 8: [394.6, 396.7, 398.7],\n",
       " 9: [575.2, 577.3, 579.4, 581.4, 583.5, 585.5, 587.6, 589.6, 591.7],\n",
       " 10: [409, 411, 413.1, 415.1, 417.2, 419.2, 421.3, 423.3, 425.4, 427.4, 429.5],\n",
       " 11: [402.8],\n",
       " 12: [454.1, 456.2, 458.2, 460.3, 462.3, 464.4, 466.4, 468.5, 470.6, 472.6],\n",
       " 13: [768.2,\n",
       "  770.3,\n",
       "  772.3,\n",
       "  774.4,\n",
       "  776.4,\n",
       "  778.5,\n",
       "  780.5,\n",
       "  782.6,\n",
       "  784.6,\n",
       "  786.7,\n",
       "  788.7,\n",
       "  790.8,\n",
       "  792.8,\n",
       "  794.9,\n",
       "  796.9,\n",
       "  799,\n",
       "  801.1,\n",
       "  803.1,\n",
       "  805.2,\n",
       "  807.2,\n",
       "  809.3,\n",
       "  811.3],\n",
       " 14: [618.4,\n",
       "  620.4,\n",
       "  622.5,\n",
       "  624.5,\n",
       "  626.6,\n",
       "  628.6,\n",
       "  630.7,\n",
       "  632.7,\n",
       "  634.8,\n",
       "  702.5,\n",
       "  704.6,\n",
       "  727.2,\n",
       "  729.2],\n",
       " 15: [739.5, 741.5, 743.6, 745.6],\n",
       " 16: [593.7,\n",
       "  595.8,\n",
       "  597.8,\n",
       "  599.9,\n",
       "  601.9,\n",
       "  604,\n",
       "  606,\n",
       "  710.7,\n",
       "  712.8,\n",
       "  714.8,\n",
       "  716.9,\n",
       "  718.9,\n",
       "  721,\n",
       "  723],\n",
       " 17: [530.1, 532.1, 534.2, 536.2, 538.3, 540.3, 542.4, 544.5, 546.5],\n",
       " 18: [404.9],\n",
       " 19: [747.7, 749.7, 868.8, 870.9, 872.9, 875, 877, 879.1, 881.1, 883.2, 885.2]}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusters_1 = dict()\n",
    "for index, band in zip(label_1, cols):\n",
    "    if index in clusters_1:\n",
    "        clusters_1[index].append(band)\n",
    "    else:\n",
    "        clusters_1[index] = [band]\n",
    "\n",
    "clusters_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [622.5,\n",
       "  624.5,\n",
       "  626.6,\n",
       "  628.6,\n",
       "  630.7,\n",
       "  632.7,\n",
       "  634.8,\n",
       "  636.8,\n",
       "  638.9,\n",
       "  640.9,\n",
       "  643,\n",
       "  645,\n",
       "  647.1,\n",
       "  649.1,\n",
       "  651.2,\n",
       "  653.3,\n",
       "  655.3,\n",
       "  657.4],\n",
       " 1: [753.8,\n",
       "  755.9,\n",
       "  757.9,\n",
       "  760,\n",
       "  762.1,\n",
       "  817.5,\n",
       "  819.5,\n",
       "  821.6,\n",
       "  823.6,\n",
       "  825.7,\n",
       "  827.7,\n",
       "  829.8,\n",
       "  831.8,\n",
       "  833.9,\n",
       "  836,\n",
       "  838,\n",
       "  840.1,\n",
       "  842.1,\n",
       "  844.2,\n",
       "  846.2,\n",
       "  848.3,\n",
       "  850.3,\n",
       "  852.4,\n",
       "  854.4,\n",
       "  856.5,\n",
       "  858.5,\n",
       "  860.6,\n",
       "  862.6],\n",
       " 2: [404.9,\n",
       "  476.7,\n",
       "  478.8,\n",
       "  480.8,\n",
       "  482.9,\n",
       "  484.9,\n",
       "  487,\n",
       "  489,\n",
       "  491.1,\n",
       "  493.1,\n",
       "  495.2,\n",
       "  497.2,\n",
       "  499.3,\n",
       "  501.3,\n",
       "  503.4],\n",
       " 3: [729.2, 731.3],\n",
       " 4: [398.7,\n",
       "  536.2,\n",
       "  538.3,\n",
       "  540.3,\n",
       "  542.4,\n",
       "  544.5,\n",
       "  546.5,\n",
       "  548.6,\n",
       "  550.6,\n",
       "  552.7,\n",
       "  554.7,\n",
       "  556.8,\n",
       "  558.8,\n",
       "  560.9,\n",
       "  562.9,\n",
       "  565,\n",
       "  567,\n",
       "  569.1,\n",
       "  571.1,\n",
       "  573.2,\n",
       "  575.2,\n",
       "  577.3,\n",
       "  579.4,\n",
       "  581.4,\n",
       "  583.5,\n",
       "  585.5,\n",
       "  587.6,\n",
       "  589.6,\n",
       "  591.7,\n",
       "  593.7,\n",
       "  595.8,\n",
       "  597.8],\n",
       " 5: [394.6, 714.8, 716.9, 718.9],\n",
       " 6: [400.8, 519.8, 521.9, 523.9, 526],\n",
       " 7: [406.9,\n",
       "  409,\n",
       "  443.9,\n",
       "  445.9,\n",
       "  448,\n",
       "  450,\n",
       "  452.1,\n",
       "  454.1,\n",
       "  456.2,\n",
       "  458.2,\n",
       "  460.3,\n",
       "  462.3,\n",
       "  464.4,\n",
       "  466.4,\n",
       "  468.5,\n",
       "  470.6,\n",
       "  472.6,\n",
       "  474.7],\n",
       " 8: [747.7,\n",
       "  749.7,\n",
       "  751.8,\n",
       "  864.7,\n",
       "  866.7,\n",
       "  868.8,\n",
       "  870.9,\n",
       "  872.9,\n",
       "  875,\n",
       "  877,\n",
       "  879.1,\n",
       "  881.1,\n",
       "  883.2,\n",
       "  885.2],\n",
       " 9: [725.1, 727.2],\n",
       " 10: [741.5, 743.6, 745.6],\n",
       " 11: [411,\n",
       "  413.1,\n",
       "  415.1,\n",
       "  417.2,\n",
       "  419.2,\n",
       "  421.3,\n",
       "  423.3,\n",
       "  425.4,\n",
       "  427.4,\n",
       "  429.5,\n",
       "  431.6,\n",
       "  433.6,\n",
       "  435.7,\n",
       "  437.7,\n",
       "  439.8,\n",
       "  441.8],\n",
       " 12: [599.9, 601.9, 604, 606, 608.1, 610.1, 612.2, 614.2, 616.3, 618.4, 620.4],\n",
       " 13: [396.7,\n",
       "  659.4,\n",
       "  661.5,\n",
       "  663.5,\n",
       "  665.6,\n",
       "  667.6,\n",
       "  669.7,\n",
       "  671.7,\n",
       "  673.8,\n",
       "  675.8,\n",
       "  677.9,\n",
       "  679.9,\n",
       "  682,\n",
       "  684,\n",
       "  686.1,\n",
       "  688.1,\n",
       "  690.2,\n",
       "  692.3,\n",
       "  694.3,\n",
       "  696.4,\n",
       "  698.4,\n",
       "  700.5,\n",
       "  702.5,\n",
       "  704.6,\n",
       "  706.6,\n",
       "  708.7,\n",
       "  710.7,\n",
       "  712.8],\n",
       " 14: [764.1,\n",
       "  766.2,\n",
       "  768.2,\n",
       "  770.3,\n",
       "  772.3,\n",
       "  774.4,\n",
       "  776.4,\n",
       "  778.5,\n",
       "  780.5,\n",
       "  782.6,\n",
       "  784.6,\n",
       "  786.7,\n",
       "  788.7,\n",
       "  790.8,\n",
       "  792.8,\n",
       "  794.9,\n",
       "  796.9,\n",
       "  799,\n",
       "  801.1,\n",
       "  803.1,\n",
       "  805.2,\n",
       "  807.2,\n",
       "  809.3,\n",
       "  811.3,\n",
       "  813.4,\n",
       "  815.4],\n",
       " 15: [737.4, 739.5],\n",
       " 16: [402.8, 505.5, 507.5, 509.6, 511.6, 513.7, 515.7, 517.8],\n",
       " 17: [528, 530.1, 532.1, 534.2],\n",
       " 18: [721, 723],\n",
       " 19: [733.3, 735.4]}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusters_10 = dict()\n",
    "for index, band in zip(label_10, cols):\n",
    "    if index in clusters_10:\n",
    "        clusters_10[index].append(band)\n",
    "    else:\n",
    "        clusters_10[index] = [band]\n",
    "\n",
    "clusters_10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'StackingClassifier'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-48-1edcb4e6653b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mStackingClassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msvm\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLinearSVC\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear_model\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'StackingClassifier'"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    15890699\n",
       "1    15890699\n",
       "2    15890699\n",
       "3    15890699\n",
       "4    15890699\n",
       "5    15890699\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comb_6 = pd.read_csv('comb_6_test.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_row = comb_6.count()[0]\n",
    "_num = 1000000\n",
    "split_num = int(total_row / _num) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "_tmp = comb_6.iloc[10:20]\n",
    "_tmp.to_csv('comb_6_tmp.csv',header=False,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0  1  2  3  4   5\n",
       "10  0  1  2  3  4  16\n",
       "11  0  1  2  3  4  17\n",
       "12  0  1  2  3  4  18\n",
       "13  0  1  2  3  4  19\n",
       "14  0  1  2  3  4  20\n",
       "15  0  1  2  3  4  21\n",
       "16  0  1  2  3  4  22\n",
       "17  0  1  2  3  4  23\n",
       "18  0  1  2  3  4  24\n",
       "19  0  1  2  3  4  25"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(split_num):\n",
    "    _split = comb_6.iloc[idx*_num: (idx+1)*_num]\n",
    "    _split.to_csv('comb_6_'+ str(idx+1)+'.csv', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hsi",
   "language": "python",
   "name": "hsi"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
